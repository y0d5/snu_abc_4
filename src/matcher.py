#!/usr/bin/env python3
"""
ìŠ¬ë¼ì´ë“œ-STT ë§¤ì¹­ ëª¨ë“ˆ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)

1ì°¨: ì‹œê°„ ê¸°ë°˜ ê· ë“± ë¶„í• 
2ì°¨: LLM ê²€ì¦ ë° ì¡°ì •
3ì°¨: ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ ì¬ë§¤ì¹­
"""

import sys
# ì¶œë ¥ ë²„í¼ë§ ë¹„í™œì„±í™”
sys.stdout.reconfigure(line_buffering=True)

import os
import json
from pathlib import Path
from dataclasses import dataclass, field
import anthropic


def load_env_file():
    """í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"""
    env_path = Path(__file__).parent.parent / ".env"
    if env_path.exists():
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

# .env íŒŒì¼ ë¡œë“œ
load_env_file()


@dataclass
class SlideMatch:
    """ìŠ¬ë¼ì´ë“œ-ë°œí™” ë§¤ì¹­ ê²°ê³¼"""
    slide_num: int
    slide_text: str
    utterances: list[dict] = field(default_factory=list)
    confidence: str = "unknown"  # high, medium, low, unknown
    llm_verified: bool = False
    notes: str = ""


def time_based_matching(
    slides_info: list[dict],
    stt_data: dict,
    total_duration_seconds: int
) -> list[SlideMatch]:
    """
    1ì°¨: í˜ì´ì§€ ë²ˆí˜¸ ìš°ì„ , ì—†ìœ¼ë©´ ì‹œê°„ ê¸°ë°˜ ê· ë“± ë¶„í•  ë§¤ì¹­

    - STTì— slide_num(í˜ì´ì§€ ë²ˆí˜¸)ì´ ìˆìœ¼ë©´ í•´ë‹¹ ìŠ¬ë¼ì´ë“œì— ì§ì ‘ ë°°ì • (ìš°ì„ )
    - ì—†ìœ¼ë©´ ê¸°ì¡´ì²˜ëŸ¼ ì‹œê°„ëŒ€ ê¸°ë°˜ìœ¼ë¡œ ë°°ì •
    """
    print("\n[3-1] ìŠ¬ë¼ì´ë“œ-STT ë§¤ì¹­ (í˜ì´ì§€ ë²ˆí˜¸ ìš°ì„ , ì‹œê°„ ê¸°ë°˜ ë³´ì¡°)")
    
    num_slides = len(slides_info)
    utterances = stt_data.get("utterances", [])
    
    if not utterances:
        print("   âš ï¸ ë°œí™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ë°œí™” ìˆ˜
    page_annotated = sum(1 for u in utterances if u.get("slide_num"))
    if page_annotated:
        print(f"   ğŸ“Œ í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ë°œí™”: {page_annotated}ê°œ (ìš°ì„  ë§¤ì¹­)")
    
    # ë§ˆì§€ë§‰ ë°œí™” ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ (ì‹œê°„ ê¸°ë°˜ ë§¤ì¹­ìš©)
    last_utterance_time = max(u["seconds"] for u in utterances)
    time_per_slide = last_utterance_time / num_slides if num_slides else 1
    
    print(f"   ì´ ìŠ¬ë¼ì´ë“œ: {num_slides}ê°œ")
    print(f"   ì´ ë°œí™”: {len(utterances)}ê°œ")
    print(f"   ë§ˆì§€ë§‰ ë°œí™” ì‹œê°„: {last_utterance_time}ì´ˆ")
    
    # ìŠ¬ë¼ì´ë“œë³„ ë§¤ì¹­ ì´ˆê¸°í™”
    matches = []
    for i, slide in enumerate(slides_info):
        match = SlideMatch(
            slide_num=slide["page_num"],
            slide_text=slide.get("text_preview", ""),
            utterances=[],
            confidence="unknown"
        )
        matches.append(match)
    
    # ê° ë°œí™”ë¥¼ ìŠ¬ë¼ì´ë“œì— ë°°ì •
    for utterance in utterances:
        slide_idx = None
        slide_num = utterance.get("slide_num")
        
        # 1) í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ìŠ¬ë¼ì´ë“œì— ë°°ì • (1-based â†’ 0-based)
        if slide_num is not None and 1 <= slide_num <= num_slides:
            slide_idx = slide_num - 1
        # 2) ì—†ìœ¼ë©´ ì‹œê°„ ê¸°ë°˜ ë°°ì •
        if slide_idx is None:
            seconds = utterance["seconds"]
            slide_idx = min(int(seconds / time_per_slide), num_slides - 1) if num_slides else 0
        
        matches[slide_idx].utterances.append(utterance)
    
    # í†µê³„ ì¶œë ¥
    empty_slides = sum(1 for m in matches if len(m.utterances) == 0)
    print(f"   â†’ ë§¤ì¹­ ì™„ë£Œ: {num_slides - empty_slides}ê°œ ìŠ¬ë¼ì´ë“œì— ë°œí™” ë°°ì •")
    print(f"   â†’ ë°œí™” ì—†ëŠ” ìŠ¬ë¼ì´ë“œ: {empty_slides}ê°œ")
    
    return matches


def llm_verify_matches(
    matches: list[SlideMatch],
    batch_size: int = 5
) -> list[SlideMatch]:
    """
    2ì°¨: LLMì„ ì‚¬ìš©í•˜ì—¬ ë§¤ì¹­ ê²€ì¦ ë° ì¡°ì •
    
    ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ì™€ ë°°ì •ëœ ë°œí™” ë‚´ìš©ì„ ë¹„êµí•˜ì—¬ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
    """
    print("\n[3-2] LLM ê²€ì¦ ì‹œì‘")
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key or api_key == "your_api_key_here":
        print("   âš ï¸ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   â†’ .env íŒŒì¼ì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        print("   â†’ LLM ê²€ì¦ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return matches
    
    client = anthropic.Anthropic(api_key=api_key)
    
    # ë°œí™”ê°€ ìˆëŠ” ìŠ¬ë¼ì´ë“œë§Œ ê²€ì¦
    slides_to_verify = [m for m in matches if m.utterances]
    total = len(slides_to_verify)
    
    print(f"   ê²€ì¦ ëŒ€ìƒ: {total}ê°œ ìŠ¬ë¼ì´ë“œ")
    
    verified_count = 0
    adjusted_count = 0
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for i in range(0, total, batch_size):
        batch = slides_to_verify[i:i+batch_size]
        
        for match in batch:
            try:
                result = verify_single_match(client, match, matches)
                if result["verified"]:
                    match.confidence = "high"
                    match.llm_verified = True
                    verified_count += 1
                else:
                    match.confidence = result.get("confidence", "low")
                    match.notes = result.get("notes", "")
                    if result.get("adjusted"):
                        adjusted_count += 1
            except Exception as e:
                print(f"   âš ï¸ ìŠ¬ë¼ì´ë“œ {match.slide_num} ê²€ì¦ ì‹¤íŒ¨: {e}")
                match.confidence = "unknown"
        
        print(f"   â†’ {min(i + batch_size, total)}/{total} ê²€ì¦ ì™„ë£Œ")
    
    print(f"   âœ… ê²€ì¦ ì™„ë£Œ: {verified_count}ê°œ ì¼ì¹˜, {adjusted_count}ê°œ ì¡°ì •ë¨")
    
    return matches


def verify_single_match(
    client: anthropic.Anthropic,
    match: SlideMatch,
    all_matches: list[SlideMatch]
) -> dict:
    """ë‹¨ì¼ ìŠ¬ë¼ì´ë“œ-ë°œí™” ë§¤ì¹­ ê²€ì¦"""
    
    # ë°œí™” ë‚´ìš© ìš”ì•½ (í˜ì´ì§€ ë²ˆí˜¸ íŒíŠ¸ í¬í•¨)
    utterance_lines = []
    page_hint_utterances = []
    for u in match.utterances[:5]:  # ìµœëŒ€ 5ê°œë§Œ
        line = f"[{u['timestamp']}] {u['speaker']}: {u['content'][:200]}"
        utterance_lines.append(line)
        if u.get("slide_num"):
            page_hint_utterances.append(f"  - {u['timestamp']} ë°œí™”: ì›ë³¸ STTì—ì„œ ìŠ¬ë¼ì´ë“œ {u['slide_num']}ë²ˆìœ¼ë¡œ í‘œì‹œë¨")
    utterance_text = "\n".join(utterance_lines)
    page_hint_block = ""
    if page_hint_utterances:
        page_hint_block = "\n## STT í˜ì´ì§€ ë²ˆí˜¸ ì •ë³´ (ìš°ì„  ê³ ë ¤):\n" + "\n".join(page_hint_utterances) + "\n"
    
    # ì¸ì ‘ ìŠ¬ë¼ì´ë“œ ì •ë³´
    slide_idx = match.slide_num - 1
    prev_slide_text = all_matches[slide_idx - 1].slide_text if slide_idx > 0 else ""
    next_slide_text = all_matches[slide_idx + 1].slide_text if slide_idx < len(all_matches) - 1 else ""
    
    prompt = f"""ë‹¹ì‹ ì€ ê°•ì˜ ìŠ¬ë¼ì´ë“œì™€ ê°•ì—° ë‚´ìš©ì„ ë§¤ì¹­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í˜„ì¬ ìŠ¬ë¼ì´ë“œ {match.slide_num}ë²ˆì— ë‹¤ìŒ ë°œí™”ë“¤ì´ ë°°ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.{page_hint_block}

## ìŠ¬ë¼ì´ë“œ {match.slide_num} í…ìŠ¤íŠ¸:
{match.slide_text[:500] if match.slide_text else "(í…ìŠ¤íŠ¸ ì—†ìŒ)"}

## ë°°ì •ëœ ë°œí™” ë‚´ìš©:
{utterance_text}

## ì´ì „ ìŠ¬ë¼ì´ë“œ ({match.slide_num - 1}ë²ˆ) í…ìŠ¤íŠ¸:
{prev_slide_text[:200] if prev_slide_text else "(ì—†ìŒ)"}

## ë‹¤ìŒ ìŠ¬ë¼ì´ë“œ ({match.slide_num + 1}ë²ˆ) í…ìŠ¤íŠ¸:
{next_slide_text[:200] if next_slide_text else "(ì—†ìŒ)"}
{"\n**STTì— í˜ì´ì§€ ë²ˆí˜¸ê°€ í‘œì‹œëœ ë°œí™”ëŠ” ì›ë³¸ ë…¹ìŒì—ì„œ í•´ë‹¹ ìŠ¬ë¼ì´ë“œë¡œ ê¸°ë¡ëœ ê²ƒì´ë¯€ë¡œ, ê·¸ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‹ ë¢°í•´ì£¼ì„¸ìš”.**" if page_hint_utterances else ""}

ì´ ë°œí™”ë“¤ì´ í˜„ì¬ ìŠ¬ë¼ì´ë“œì— ì ì ˆí•˜ê²Œ ë§¤ì¹­ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{{
  "match_quality": "good" | "partial" | "poor",
  "confidence": "high" | "medium" | "low",
  "reasoning": "íŒë‹¨ ì´ìœ  (í•œ ë¬¸ì¥)",
  "suggested_slide": í˜„ì¬ ìŠ¬ë¼ì´ë“œê°€ ì ì ˆí•˜ë©´ {match.slide_num}, ì•„ë‹ˆë©´ ë” ì ì ˆí•œ ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸
}}"""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=500,
        messages=[{"role": "user", "content": prompt}]
    )
    
    # ì‘ë‹µ íŒŒì‹±
    response_text = response.content[0].text
    
    try:
        # JSON ì¶”ì¶œ
        import re
        json_match = re.search(r'\{[^{}]*\}', response_text, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group())
            
            verified = result.get("match_quality") in ["good", "partial"]
            return {
                "verified": verified,
                "confidence": result.get("confidence", "medium"),
                "notes": result.get("reasoning", ""),
                "adjusted": result.get("suggested_slide") != match.slide_num
            }
    except json.JSONDecodeError:
        pass
    
    return {"verified": False, "confidence": "unknown", "notes": "íŒŒì‹± ì‹¤íŒ¨"}


def refine_uncertain_matches(matches: list[SlideMatch]) -> list[SlideMatch]:
    """
    3ì°¨: ë¶ˆí™•ì‹¤í•œ ë§¤ì¹­ ì¬ì¡°ì •
    
    confidenceê°€ lowì¸ ë§¤ì¹­ë“¤ì„ ì¸ì ‘ ìŠ¬ë¼ì´ë“œì™€ ë¹„êµí•˜ì—¬ ì¬ì¡°ì •
    """
    print("\n[3-3] ë¶ˆí™•ì‹¤í•œ ë§¤ì¹­ ì¬ì¡°ì •")
    
    uncertain = [m for m in matches if m.confidence == "low"]
    
    if not uncertain:
        print("   â†’ ì¬ì¡°ì •ì´ í•„ìš”í•œ ìŠ¬ë¼ì´ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return matches
    
    print(f"   ì¬ì¡°ì • ëŒ€ìƒ: {len(uncertain)}ê°œ ìŠ¬ë¼ì´ë“œ")
    
    # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ë°œí™” ë‚´ìš©ì— ìŠ¬ë¼ì´ë“œ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    adjusted_count = 0
    
    for match in uncertain:
        # í˜„ì¬ ìŠ¬ë¼ì´ë“œì˜ í‚¤ì›Œë“œ
        current_keywords = set(match.slide_text.lower().split()) if match.slide_text else set()
        
        # ë°œí™” ë‚´ìš©ì˜ í‚¤ì›Œë“œ
        utterance_text = " ".join([u["content"] for u in match.utterances])
        utterance_keywords = set(utterance_text.lower().split())
        
        # í‚¤ì›Œë“œ ê²¹ì¹¨ ì •ë„ ê³„ì‚°
        if current_keywords:
            overlap = len(current_keywords & utterance_keywords) / len(current_keywords)
            if overlap > 0.1:  # 10% ì´ìƒ ê²¹ì¹˜ë©´ ì ì ˆí•œ ê²ƒìœ¼ë¡œ íŒë‹¨
                match.confidence = "medium"
                match.notes += " (í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¡°ì •)"
                adjusted_count += 1
    
    print(f"   âœ… {adjusted_count}ê°œ ìŠ¬ë¼ì´ë“œ confidence ì¡°ì •ë¨")
    
    return matches


def run_matching(output_dir: Path) -> list[SlideMatch]:
    """
    ì „ì²´ ë§¤ì¹­ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    """
    print("\n" + "=" * 70)
    print("ğŸ”„ Step 3: ìŠ¬ë¼ì´ë“œ-STT ë§¤ì¹­ ì‹œì‘")
    print("=" * 70)
    
    # ë°ì´í„° ë¡œë“œ
    slides_info_path = output_dir / "slides_info.json"
    stt_path = output_dir / "stt_parsed.json"
    metadata_path = output_dir / "metadata.json"
    
    with open(slides_info_path, 'r', encoding='utf-8') as f:
        slides_info = json.load(f)
    
    with open(stt_path, 'r', encoding='utf-8') as f:
        stt_data = json.load(f)
    
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    # STT duration íŒŒì‹± (ì˜ˆ: "94ë¶„ 3ì´ˆ")
    duration_str = metadata.get("stt_duration", "0ë¶„")
    import re
    mins = re.search(r'(\d+)ë¶„', duration_str)
    secs = re.search(r'(\d+)ì´ˆ', duration_str)
    total_seconds = (int(mins.group(1)) * 60 if mins else 0) + (int(secs.group(1)) if secs else 0)
    
    # 1ì°¨: ì‹œê°„ ê¸°ë°˜ ë§¤ì¹­
    matches = time_based_matching(slides_info, stt_data, total_seconds)
    
    # 2ì°¨: LLM ê²€ì¦
    matches = llm_verify_matches(matches)
    
    # 3ì°¨: ë¶ˆí™•ì‹¤í•œ ë§¤ì¹­ ì¬ì¡°ì •
    matches = refine_uncertain_matches(matches)
    
    # ê²°ê³¼ ì €ì¥
    result_path = output_dir / "slide_matches.json"
    result_data = [
        {
            "slide_num": m.slide_num,
            "utterance_count": len(m.utterances),
            "confidence": m.confidence,
            "llm_verified": m.llm_verified,
            "notes": m.notes,
            "utterances": m.utterances
        }
        for m in matches
    ]
    
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)
    
    print(f"\n   âœ… ë§¤ì¹­ ê²°ê³¼ ì €ì¥: {result_path.name}")
    
    # í†µê³„
    high_conf = sum(1 for m in matches if m.confidence == "high")
    medium_conf = sum(1 for m in matches if m.confidence == "medium")
    low_conf = sum(1 for m in matches if m.confidence == "low")
    
    print("\n" + "-" * 70)
    print("ğŸ“Š ë§¤ì¹­ ê²°ê³¼ ìš”ì•½")
    print("-" * 70)
    print(f"   ë†’ì€ ì‹ ë¢°ë„ (high):   {high_conf}ê°œ")
    print(f"   ì¤‘ê°„ ì‹ ë¢°ë„ (medium): {medium_conf}ê°œ")
    print(f"   ë‚®ì€ ì‹ ë¢°ë„ (low):    {low_conf}ê°œ")
    print("=" * 70)
    
    return matches


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        output_dir = Path(sys.argv[1])
        run_matching(output_dir)
    else:
        print("Usage: python matcher.py <output_dir>")
